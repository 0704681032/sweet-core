\documentclass[preprint,10pt]{sigplanconf}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{gastex}
\usepackage{graphics}
\usepackage{listings}
\usepackage{microtype}
\input{brackets}
\input{definitions}
\authorinfo{Tim Disney}{UC Santa Cruz}{}
\authorinfo{Nate Faubion}{}{}
\authorinfo{David Herman}{Mozilla}{}
\renewcommand{\author}[1]{}
\author{Tim Disney}
\date{\today}
\title{Sweet.js - Hygienic Macros for JavaScript}
\hypersetup{
  pdfkeywords={},
  pdfsubject={Sweet.js - Macros for JavaScript}}
\begin{document}

\maketitle

\section{Introduction}
\label{sec-1}

Sweet.js is a new hygienic macro system for JavaScript.

Macros systems have a long history in the design of extensible
programming languages going back at least to lisp as a tool to provide
programmers syntactic flexibility.

While powerful macro systems have been used extensively in lisp
derived languages there has been considerable less movement for macros
systems for languages with an expression based syntax such as
JavaScript. This is due to a variety of technical reasons that have
held back macro systems in expression based languages which we address
in this paper.

Recently the Honu project has shown how to overcome some of the
existing challenges in developing a macro system for expression based
language. The Honu technique was designed for an idealized JavaScript
like language. In this paper we show how to extend the ideas of Honu
for full JavaScript and present additional techniques that target
expression based languages.

The design of sweet.js attempts to overcome the following technical
challenges: 

\begin{itemize}
\item a correct implementation of \texttt{read} that structures the token stream
before expansion begins
\item parser class annotation (e.g. \texttt{:expr}) in patterns to allow macro
authors easier declaration of a macro shape
\item operator overloading
\item infix macros
\item the \texttt{invoke} primitive to allow custom parser classes and more
powerful matching
\end{itemize}
\section{Overview}
\label{sec-2}
TODO: syntax, main features etc\ldots
\section{Read}
\label{sec-3}

The syntax of JavaScript presents a challenge to correctly implement
the critical \texttt{read} function. This challenge is not present in Honu
because their language is an idealized syntax that misses the
problematic interaction of delimiters and regular expression literals.

TODO: motivate \texttt{read} with examples etc.

\subsection{Proof of \texttt{read}}
\label{sec-3-1}

We first define a simplified grammar that captures just the essential
complexity we want to address, namely the interaction between
the division symbol \texttt{/} and the regular expression literal
\texttt{/x/}.

\[
\begin{array}{rrl}
  \Tok &::=& x ~|~ /
  \\
  \TT &::=& x ~|~ / ~|~ /x/
  \\
\end{array}
\]

We also define \( \textit{Expr}' \) with the same productions as \(
\textit{Expr} \) but defined over \( \TT^{*} \) instead of \( \Tok^{*}
\). So the terminal \( /x/ \) in the second production of \(
\textit{Expr} \) is three distinct tokens (\( /, x, \) and \( /
\)) while it is a single token in \( \textit{Expr}' \).


\begin{theorem}[\label{thrm:read}Read is correct]\mbox{}

  \( \forall s \in \Tok. \)
  \[
  \{ e \mid s \in \gprods{Program}{e} \}
  =
  \{ e \mid \readfn{s}{\epsilon} \in \gprods{Program}{e}' \}
  \]
\end{theorem}
\begin{proof}\mbox{}
  
By showing set inclusion. Details in the appendix.
\end{proof}

\begin{displayfigure*}{\label{fig:grammar}Simple JS Grammar}
\[
\begin{array}{lcl}
  \gprod{PrimaryExpr}{p}{p} &::=& \epsilon \\
  \gprod{PrimaryExpr}{p}{\var} &::=& \var \\
  \gprod{PrimaryExpr}{p}{\rett} &::=& \re \\
  \\
  \gprod{CallExpr}{p}{e} &::=& \gprod{PrimaryExpr}{p}{e} \\
  \gprod{CallExpr}{p}{\call{e}{e'}} 
  &::=& 
  \call{\gprod{PrimaryExpr}{p}{e}}{
    \gprod{Expr}{\epsilon}{e'}
  } \\
  \\
  \gprod{Expr}{p}{e} &::=& \gprod{CallExpr}{p}{e} \\
  \gprod{Expr}{p}{e ~\div~ e'}
  &::=&
  \gprod{Expr}{p}{e} ~\div~ \gprod{Expr}{e~\div}{e'} \\
  \gprod{Expr}{p}{e ~\plus~ e'}
  &::=&
  \gprod{Expr}{p}{e} ~\plus~ \gprod{Expr}{e~\plus}{e'} \\
  \\
  \gprod{Statement}{p}{e} &::=& \gprod{Expr}{p}{e} \\
  \gprod{Statement}{p}{\ifstate{e}{~e'}} 
  &::=& 
  \ifstate{
    \gprod{Expr}{\epsilon}{e}  
  }{
    ~\gprod{Statement}{p~\ifstate{e}{}}{e'} 
  } \\
  \gprod{Statement}{p}{\ifelsestate{e}{~e'}{~e''}} 
  &::=& 
  \ifelsestate{
    \gprod{Expr}{\epsilon}{e}
  }{
    ~\gprod{Statement}{p~\ifstate{e}{}}{e'}
  }{
    ~\gprod{Statement}{p~\ifelsestate{e}{}}{e''}  
  } \\
  \\
  \gprods{Program}{e} &::=& \gprod{Statement}{\epsilon}{e} \\
  \gprods{Program}{e} &::=& \gprod{FunctionDeclaration}{\epsilon}{e}

\end{array}
\]  
\end{displayfigure*}

\begin{displayfigure*}{\label{fig:read}Read Algorithm}
  
\[
  \begin{array}{lcl}
    \readfn{/\cdot \textrm{rest}}{\textrm{prefix}\cdot x}
    &=&
    \cons{/}{
      \readfn{\textrm{rest}}{
        \textrm{prefix}\cdot x\cdot /
      }
    }
    \\
    \readfn{/\cdot \textrm{rest}}{\textrm{prefix}\cdot /x/}
    &=&
    \cons{/}{
      \readfn{\textrm{rest}}{
        \textrm{prefix}\cdot /x/ \cdot /
      }
    }
    \\
    \readfn{/\cdot x \cdot /\cdot\textrm{rest}}{\textrm{prefix}\cdot /}
    &=&
    \cons{/x/}{
      \readfn{\textrm{rest}}{
        \textrm{prefix}\cdot / \cdot /x/
      }
    }
    \\
    \readfn{/\cdot x \cdot /\cdot\textrm{rest}}{\epsilon}
    &=&
    \cons{/x/}{
      \readfn{\textrm{rest}}{/x/}
    }
    \\
    \readfn{x \cdot \textrm{rest}}{\textrm{prefix}}
    &=&
    \cons{x}{
      \readfn{\textrm{rest}}{\textrm{prefix}\cdot x}
    }
    \\
    \readfn{\epsilon}{\textrm{prefix}}
    &=&
    \epsilon
  \end{array}
\]
\end{displayfigure*}

\section{Enforestation}
\label{sec-4}

The core algorithm introduced by Honu is called \emph{enforestation} which
is basically responsible for expanding macros and building a partial
syntax tree with enough structure to match on parse classes. Sweet.js
implements this algorithm mostly as described with some additions to
provide infix macros and invoke pattern classes described below.

\subsection{Infix Macros}
\label{sec-4-1}
The macros we have described so far must all be prefixed by the macro
identifier and syntax after the macro name is matched. This is
sufficient for many kinds of macros but some syntax forms require the
macro identifier to sit between patterns.

Honu addresses this need in a limited way by providing a way to define
new binary and unary operators which during expansion can manipulate
their operators. However, those operators must be fully expanded and
must match as an expression.

Sweet.js provides \emph{infix macros} which allows a macro identifier to
match syntax before it. For example, the following implements
ES6-style arrow functions via infix macros:

\begin{verbatim}
macro (=>) {
    rule infix {
        ($params ...) | { $body ... }
    } => {
        function ($params ...) {
            $body ...
        }
    }
}

var id = (x) => { return x; }
\end{verbatim}

The macros we have described so far must all be prefixed by the macro
identifier and syntax after the macro name is matched. This is
sufficient for many kinds of macros but some syntax forms require the
macro identifier to sit between patterns.

Honu addresses this need in a limited way by providing a way to define
new binary and unary operators which during expansion can manipulate
their operators. However, those operators must be fully expanded and
must match as an expression.

Sweet.js provides \emph{infix macros} which allows a macro identifier to
match syntax before it. For example, the following implements
ES6-style arrow functions via infix macros:

\begin{verbatim}
macro (=>) {
    rule infix {
        ($params ...) | { $body ... }
    } => {
        function ($params ...) {
            $body ...
        }
    }
}
var id = (x) => { return x; }
\end{verbatim}

This is accomplished by simply providing the state of previously
expanded syntax to macro transformers. Macros may then consume from
either ends as needed, yielding new previous and subsequent syntax. At
first glance, this can appear brittle:

\begin{verbatim}
var foo = bar(x) => { return x; }
\end{verbatim}

We've juxtaposed the \verb!=>! macro next to a function call, which we did
not intend to be valid syntax. A naive expansion results in unparsable
code:

\begin{verbatim}
var foo = bar function(x) { return x; }
\end{verbatim}

In more subtle cases, a naive expansion can result in parsable code
with incorrect semantics. [Example needed?] To preserve the integrity
of previously expanded syntax, we verify that an infix macro only
matches previous syntax on boundaries delimited by the partial syntax
tree we've built. The syntax tree would show \verb!bar(x)! as a complete
function call term. Consuming the parentheses would result in a split
term and is disallowed, failing the rule. In practice, this has proven
to be an intuitive restriction. [Elaborate?]

The primary limitation of infix macros is they do not obey precedence
and associativity. They stand as a complement to Honu operators, not
as a replacement, for when an infix form does not adhere to operator
semantics, much like the \verb!=>! macro. Its left-hand-side and
right-hand-side are not arbitrary expressions but must match a
specific form. Additionally, it would need a precedence of infinity so
as to always bind tighter than other operators.

\subsection{Invoke and Pattern Classes}
\label{sec-4-2}

[Something about default pattern classes and `:expr`...]

Pattern classes are extensible via the \verb!invoke! class which is
parameterized by a macro name.

\begin{verbatim}
macro color {
  rule { red } => { red }
  rule { green } => { green }
  rule { blue } => { blue }
}
macro colors_options {
  rule { ($opt:invoke(color) ...) } => { ... }
}
\end{verbatim}

The macro is essentially inserted into the token stream. If the
expansion succeeds, the result will be loaded into the pattern
variable, otherwise the rule will fail. We've added sugar so that any
non-primitive pattern classes are interpretted as \verb!invoke!
parameterized by the custom class. We've also added identity rules to
shorten definitions of simple custom classes.

\begin{verbatim}
macro color {
  rule { red }
  rule { green }
  rule { blue }
}
macro colors_options {
  rule { ($opt:color (,) ...) } => { ... }
}
\end{verbatim}

These macros may return an optional pattern environment which will be
scoped and loaded into the invoking macro's pattern environment. This
lets us define Honu-style pattern classes as simple macro-generating
macros.

\begin{verbatim}
macro color {
  ...
}
macro number {
  ...
}
// `pattern` is just a macro-generating macro
pattern color_value { $color:color $num:number }

macro color_options {
  rule { ($opt:color_value (,) ...) } => {
    var cols = [$opt$color (,) ...];
    var nums = [$opt$num (,) ...];
  }
}

\end{verbatim}

...?

\section{Hygiene}
\label{sec-5}

Mostly straightforward implementation from scheme with some details to
handle \texttt{var}.
\section{Implementation}
\label{sec-6}
Sweet.js is written in JavaScript and runs in the major JS
environments (\ie the brower and node.js). This is in contrast to Honu
which translates its code to Racket code and reuses the hygienic
expansion machinery already built in Racket. While this simplifies
the implementation of Honu it also requires an installation of Racket
which in some cases is not feasible (\eg sweet.js is able to run in
mobile device browsers).
\section{Related Work}
\label{sec-7}

\begin{itemize}
\item Scheme/Racket
\item Honu
\item Template Haskell
\item Nemerle
\item Scala
\item Closure
\end{itemize}
\section{Conclusion}
\label{sec-8}
% Emacs 24.3.1 (Org mode 8.2.5h)

\appendix

\section{Read Proof}

To help reason over prefixes we define the following set of token tree
words that end with a literal:
\[
\begin{array}{rcl}
\ewl &::=& \{t \mid \forall s \in \TT^{*}.~t = s \cdot \var
~\textrm{or}~ t = s \cdot \rett \}
\end{array}
\]

\begin{lemma}[\label{lem:readPrimaryExpr}Read PrimaryExpr]\mbox{}

  \( \forall s \in \Tok^{*},~p \in \neg \ewl. \)
  \[
  \{ e \mid s \in \gprod{PrimaryExpr}{p}{e} \}
  =
  \{ e \mid \readfn{s}{p} \in \gprod{PrimaryExpr}{p}{e}' \}
  \]
\end{lemma}
\begin{proof}
  We first show 
  \( \{ e \mid s \in \gprod{PrimaryExpr}{p}{e} \} \subset
  \{ e \mid \readfn{s}{p} \in \gprod{PrimaryExpr}{p}{e}' \}
  \)
  by cases on \( s \in \gprod{PrimaryExpr}{p}{e} \):
  \begin{itemize}

  \item Case \( \epsilon \). Then \( s = \epsilon \in
    \gprod{PrimaryExpr}{p}{p} \) and \(
    \readfn{\epsilon}{p} = \epsilon \in \gprod{PrimaryExpr}{p}{p}' \).

  \item Case \( \var \). Then \( s = \var \in
    \gprod{PrimaryExpr}{p}{\var} \) and \( \readfn{\var}{p} = x \in
    \gprod{PrimaryExpr}{p}{\var}' \).

  \item Case \( \re \). Then \( s = \re \in
    \gprod{PrimaryExpr}{p}{\rett} \) and since \( p \in \neg \ewl \)
    then \( \readfn{\re}{p} = \rett \in \gprod{PrimaryExpr}{p}{\rett}' \).

  \end{itemize}
  To show 
  \( 
  \{ e \mid \readfn{s}{p} \in \gprod{PrimaryExpr}{p}{e}' \}
  \subset
  \{ e \mid s \in \gprod{PrimaryExpr}{p}{e} \} 
  \) the cases are similar to the above.
\end{proof}

\begin{lemma}[\label{lem:readCallExpr}Read CallExpr]\mbox{}

  \( \forall s \in \Tok^{*},~p \in \neg \ewl. \)
  \[
  \{ e \mid s \in \gprod{CallExpr}{p}{e} \}
  =
  \{ e \mid \readfn{s}{p} \in \gprod{CallExpr}{p}{e}' \}
  \]
\end{lemma}
\begin{proof}
  We first show 
  \( \{ e \mid s \in \gprod{CallExpr}{p}{e} \} \subset
  \{ e \mid \readfn{s}{p} \in \gprod{CallExpr}{p}{e}' \}
  \)
  by cases on \( s \in \gprod{CallExpr}{p}{e} \):
  \begin{itemize}

  \item Case \( \gprod{PrimaryExpr}{p}{e} \). By Lemma \ref{lem:readPrimaryExpr}.

  \item Case \( \call{\gprod{PrimaryExpr}{p}{e}}{\gprod{Expr}{\epsilon}{e'}} \).
  \end{itemize}
\end{proof}

\begin{lemma}[\label{lem:readExpr}Read Expr]
  \( \forall s \in \Tok^{*},~p \in \neg \ewl. \)
  \[
  \{ e \mid s \in \gprod{Expr}{p}{e} \}
  =
  \{ e \mid \readfn{s}{p} \in \gprod{Expr}{p}{e}' \}
  \]
\end{lemma}
\begin{proof}
  We first show 
  \( \{ e \mid s \in \gprod{Expr}{p}{e} \} \subset
  \{ e \mid \readfn{s}{p} \in \gprod{Expr}{p}{e}' \}
  \)
  by cases on \( s \in \gprod{Expr}{p}{e} \):
  \begin{itemize}
  \item Case \( \gprod{CallExpr}{p}{e} \). By Lemma \ref{lem:readCallExpr}.

  \item Case \( \gprod{Expr}{p}{e} ~\div~ \gprod{Expr}{e~\div}{e'} \). 
    Then \( s = s' \cdot \div \cdot s'' \) where \( s' \in
    \gprod{Expr}{p}{e'} \) and \( s'' \in \gprod{Expr}{e'~\div}{e''}
    \). By induction \( \readfn{s'}{p} \in \gprod{Expr}{p}{e'}' \) and
    by Lemma \ref{something} \( e' \in \ewl \) so \( \readfn{\div
      \cdot s''}{e'} = \div \cdot \readfn{s''}{e'~\div} \) so by
    induction \( \readfn{s''}{e'~\div} \in \gprod{Expr}{e'~\div}{e''}' \)
  \item .
  \end{itemize}
\end{proof}

\begin{theorem}[\label{thrm:read}Read is correct]\mbox{}

  \( \forall s \in \Tok. \)
  \[
  \{ e \mid s \in \gprods{Program}{e} \}
  =
  \{ e \mid \readfn{s}{\epsilon} \in \gprods{Program}{e}' \}
  \]
\end{theorem}
\begin{proof}\mbox{}
  
By showing set inclusion. Details in the appendix.
\end{proof}
\end{document}