\documentclass[preprint,10pt]{sigplanconf}
% \documentclass[onecolumn]{sigplanconf-onecolumn}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{stmaryrd}
\usepackage{amssymb}
\usepackage{gastex}
\usepackage{graphics}
\usepackage{listings}
\usepackage{microtype}
\usepackage{mathtools}
\usepackage{color}
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}


\input{brackets}
\input{definitions}
\authorinfo{Tim Disney}{UC Santa Cruz}{}
\authorinfo{Nate Faubion}{}{}
\authorinfo{David Herman}{Mozilla}{}
\authorinfo{Cormac Flanagan}{UC Santa Cruz}{}
\renewcommand{\author}[1]{}
\author{Tim Disney}
\date{\today}
\title{Sweet.js - Hygienic Macros for JavaScript}
\hypersetup{
  pdfkeywords={},
  pdfsubject={Sweet.js - Macros for JavaScript}}
\begin{document}


\lstdefinelanguage{JavaScript}{
  keywords={macro, typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{black}\textbf,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray},
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{darkgray}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   extendedchars=true,
   % basicstyle=\ttfamily,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}


\maketitle

\abstract{Sweet.js is a hygienic macro system for JavaScript.}

\section{Introduction}
\label{sec-1}

Expressive macros systems have a long history in the design of
extensible programming languages going back to Lisp and Scheme
\cite{Kohlbecker1987,Foderaro1983} as a powerful tool that enables
programmers to craft their own languages.

While macro systems have found success in the Lisp-derived languages,
they have not been widely adopted in languages such as JavaScript. In
part, this failure is due to the difficulty in implementing macro
systems in languages that are not fully delimited. A key feature of a
sufficiently expressive macro system is the ability for macros to
manipulate unparsed and unexpanded subexpressions. In a language with
parentheses like Scheme, manipulating unparsed subexpressions is
simple:
\begin{lstlisting}
(if (> denom 0)
    (/ x denom)
    (error "divide by zero"))
\end{lstlisting}
The Scheme \emph{reader} converts the source string into nested
s-expressions which macros can easily manipulate. Since each
subexpression of the \lstinline!if! form is a fully delimited
s-expression, it is easy to implement a form like \lstinline!if! as a
macro.

% A language with richer syntax like JavaScript complicates this
% process:
% \begin{lstlisting}
% if (denom > 0)
%   x / denom;
% else
%   throw "divide by zero";
% \end{lstlisting}
% Without fully parsing, it is difficult to know where 

Conceptually, the Scheme compiler pipeline lexes a source string into
a sequence of tokens which are then read into s-expressions before
being macro expanded and parsed into an abstract syntax tree:
\[
\textit{lexer} \xrightarrow{\textit{Token}^{*}}
\textit{reader} \xrightarrow{\textit{Sexpr}}
\textit{expander/parser} \xrightarrow{\textit{AST}}
\]

As a first step to designing a Scheme-like macro system for
JavaScript, it is necessary to introduce a read step to the compiler
pipline. However, the design of a correct reader for full JavaScript
turns out to be surprisingly subtle, due to ambiguities in how regular
expression literals (such as \lstinline!/[0-9]*/!) and the divide
operator (\lstinline!/!) should be lexed. In traditional JavaScript
compilers the parser and lexer are intertwined. Rather than run the
entire program through the lexer once to get a sequence of tokens, the
parser calls out to the lexer from a given grammatical context with a
flag to indicate if the lexer should accept a regular expression or
divide operator.
\[
\textit{lexer} \xleftrightharpoons[\textit{Token}^{*}]{\textit{feedback}}
\textit{parser} \xrightarrow{\textit{AST}}
\]
So, it is necessary to separate the parser and lexer in order to
implement a macro system for JavaScript. Our system,
sweet.js\footnote{http://sweetjs.org}, implements such a separated
reader that converts a sequence of tokens into a sequence of token
trees (similar to s-expressions) without feedback from the parser.
\[
\textit{lexer} \xrightarrow{\textit{Token}^{*}}
\textit{reader} \xrightarrow{\textit{TokenTree}^{*}}
\textit{expander/parser} \xrightarrow{\textit{AST}}
\]
This enables us to finally separate the JavaScript lexer and parser
and build a fully hygienic macro system for JavaScript.

Our work builds on techniques pioneered by Honu
\cite{Rafkind2012,Rafkind2013}, which is a macro system for a
JavaScript-like language. The Honu language does not support regular
expression literals like JavaScript which simplifies their reader.

We make the following contributions:

\begin{itemize}
\item a reader implementation and proof that separates the lexer from
  the parser.
\item the ability to define infix macros that match on arbitrary
  surrounding syntax.
\item the \texttt{invoke} primitive to allow custom parser classes and
  more powerful matching
\end{itemize}

\section{Overview}

The sweet.js system provides two kinds of macros: \emph{rule} macros
(analogous to \lstinline!syntax-rules! in Scheme) and \emph{case}
macros (analogous to \lstinline!syntax-case! in Scheme). Rule macros
are the simpler of the two and work by matching on a pattern and
generating a template:

\begin{lstlisting}
macro <name> {
  rule { <pattern> } => { <template> }
}
\end{lstlisting}

For example, the following macro introduces a new function definition
form:

\begin{lstlisting}
macro def {
  rule { 
    $name ($params (,) ...) { $body ... } 
  } => {
    function $name ($params ...) {
      $body ...
    }
  }
}
def id (x) { return x; }
// expands to:
// function id (x) { return x; }
\end{lstlisting}

The pattern is matched against the syntax following the macro name.
Identifiers in a pattern that begin with \lstinline!$! are
\emph{pattern variables} and bind the syntax they match in the
template (identifiers that do not begin with \lstinline!$! are matched
literally). The ellipses (\lstinline!$params (,) ...!) mean match zero or more
tokens separated by commas.

The above example show the power of matching delimited groups of
syntax (\ie matching all the tokens inside the function body). In
order for macros to be convenient in a language like JavaScript it is
necessary to have the ability to match logical groupings of syntax
that are not fully delimited. For example, consider the
\lstinline!let! macro:

\begin{lstlisting}
macro let {
  rule { $id = $init:expr } => {
    var $id = $init
  }
}
let x = 40 + 2;
// expands to:
// var x = 40 + 2;
\end{lstlisting}

The initialization of a \lstinline!let! can be an arbitrary expression
so we use the \emph{pattern class} \lstinline!:expr! to match on an
expression so in this example the entire expression \lstinline!40 + 2!
is bound to \lstinline!$init!.

\textbf{(some better examples than def and var?)}

Along with the template-based rule macros, sweet.js also provides the
more powerful case macros. Instead of a template, the body of a case
macro is JavaScript that is run when the macro is invoked.

\begin{lstlisting}
macro log {
  case {_ ($msg) } => {
    // need a good example here...
  }
}
\end{lstlisting}



\section{Reading JavaScript}
\label{sec:read}

Parsers give structure to unstructured source code. In parsers without
macro systems this is usually accomplished by 
a lexer (which converts a character stream to a token stream) and a
parser (which converts the token stream into an AST according to a
context-free grammar).

A macro system must transform code before it reaches the parser, but
in order to implement expressive macros it requires more structured
input than a simple token stream.

In Lisp and Scheme, this additional structure is provided by the read
function, that transforms a token stream into an s-expression by
matching delimiters. By operating on the s-expression representation,
macros can manipulate whole delimited chunks of code.

While this is obviously a requirement in an fully delimited language
like Lisp and Scheme, it is also important in languages such as
JavaScript that are not entirely delimited.

\textbf{TODO: class example to show the delimiters?}

The design of a correct reader for full JavaScript turns out to be
surprisingly subtle, due to ambiguities in how regular expression
literals (such as \lstinline!/[0-9]*/!) and the divide operator
(\lstinline!/!) should be lexed.

Our macro system includes a reader that transforms a stream of flat
tokens into a stream of more structured \emph{token trees}, by
matching delimiters.

Unfortunately, the syntax of JavaScript presents a challenge to
correctly implement the \texttt{read} function. In particular, one of
the syntax features of JavaScript is support for regular expression
literals, which are formed with the forward slash \lstinline!/!.
Delimiters are valid inside of a regular expression literal so the
reader must not match delimiters inside of a regular expression
literal otherwise it would break the true delimiter structure of the
program.

\begin{lstlisting}
function makeRegex() {
  return /}/;
}
\end{lstlisting}

Since the reader must ignore delimiters inside regular expression
literals, it must know when it is reading between the literal's
slashes. However, slash is also used as the divide operator in
JavaScript. So, in order for the reader to ignore delimiters inside of
regex literals it must first decide if a slash is the beginning of a
literal or a divide operator. Unfortunately this is somewhat
complicated for JavaScript.

Traditionally, JavaScript parsers are not separated from the lexer;
the parser calls the lexer with a flag indicating if the grammatical
context accepts either a regular expression literal or a divide token.
For JavaScript parsers this technique is sufficient but a macro
expander requires the separation of the lexer and reader from the
parser.

Note that this problem is not present in Honu since their language
does not include regular expression literals.

A key novelty in sweet.js is the design and implementation of a
correct version of read for full ES5 JavaScript\footnote{Our
  implementation also has initial support for the upcoming ES6
  version of JavaScript}. 
For clarity of presentation, this paper
describes the implementation of read for the subset of JavaScript
shown in Figure \ref{fig:grammar} which retains the essential
complications of a correct version of read but elides the full details
of the entire JavaScript language.

Read takes a sequence of tokens and produces a sequence of token
trees. Tokens are punctuators (\texttt{+}, \div, \texttt{:},
\texttt{;}, \texttt{=}, \texttt{.}), keywords (\texttt{return},
\texttt{function}, \texttt{if}), variables (\( x \)), and delimiters
(\texttt{\{}, \texttt{(}, \texttt{\}}, \texttt{)}). We write a
sequence of tokens separated by a dot so the source string
``\lstinline!foo(/x/)!'' is lexed into the sequence of six tokens
\( \texttt{foo}\cdot \texttt{(} \cdot \div \cdot \var \cdot \div \cdot \texttt{)} \).

A token tree is similar to a token with 
the addition of the regular
expression literal (\( \rett \)) and instead of 
individual opening and
closing delimiter tokens a delimiter nests a sequence of inner token
trees (\eg the sequence \( \texttt{foo} \cdot \texttt{(} \cdot
\div \cdot \var \cdot \div \cdot \texttt{)} \) would be
the token tree \( \texttt{foo} \cdot \parens{\rett} \)).

The key idea of read is to maintain of prefix of already read token
trees. When the reader comes to a slash and needs to decide if it
should read the slash as a divide token or the start of a regular
expression literal it consults the prefix. Looking back at most five
tokens trees in the prefix is sufficient to disambiguate the slash
token.

Some of the cases of read are relatively obvious. For example, if the
token just read was one of the binary operators (\eg
\lstinline!100 + /x/g!) the slash will always be a regular expression
literal. 

Other cases require additional context to disambiguate. For example,
if the previous token tree was a parentheses (\eg dividing the result
of a call \lstinline!foo(100) / 10!) then slash will be the divide
operator \emph{unless} the token tree before the parentheses was the
keyword \texttt{if} in which case it is actually the start of a
regular expression (since single statement \texttt{if }bodies do not require
braces).

\begin{lstlisting}
if (x) /y/g  
\end{lstlisting}

One of the most complicated cases is a slash following curly braces.
Part of the  complication here is that curly braces can be either an object
literal (in which case the slash should be a divide) or it could be a
block (in which case the slash should be a regular expression) but
even more problematic is that both object literals and blocks with
labeled statements can nest:

\begin{lstlisting}
{
x:{y: z} /x/g  // regex
}
\end{lstlisting}

The outer curly brace is a block with a labeled statement
\lstinline!x!, which is another block with a labeled statement
\lstinline!y! followed by a regular expression literal.

But if we slightly change the code the outer curly braces become an
object literal and \lstinline!x! is a property so the inner curly
braces are also an object literal and thus the slash is a divide operator.

\begin{lstlisting}
o = {
x:{y: z} /x/g  // divide
}
\end{lstlisting}

While it is unlikely that a programmer would attempt to intentionally
perform division on an object literal, it is not a parse error. In
fact, this is not even a runtime error since JavaScript will
implicitly convert the object to a number (technically
\lstinline!NaN!) and then perform the division (yielding
\lstinline!NaN!).

The reader handles these cases by checking if the prefix of a curly
brace block forces the curly to be an object literal or a statement
block and then setting a boolean flag to be used while reading the
tokens inside of the braces.

\subsection{Proving Read}

To show that our read algorithm correctly distinguishes between the
divide operator and a regular expression literal, we show that
a parser defined over normal tokens produces the same AST as a parser
defined over token trees produced from read.

The parser for normal tokens is defined in Figure \ref{fig:grammar}. A
parser for the nonterminal \( \gprod{Program}{} \) is a function from a
sequence of tokens to an AST.
\[
\gprod{Program}{} :: \Tok^* \rightarrow \textit{AST}
\]
We use the notation $\gprod{Program}{e} ::= \gprod{SourceElements}{e}$
to mean match the input sequence with $\gprod{SourceElements}{e}$ and
produce the resulting AST $e$.

Note that the grammar we present here is a simplified version of the
grammar specified in the ECMAScript standard \cite{International2011}
and many of the nonterminal names we use here correspond to shortened
versions of nonterminals in the standard.

% The AST for our simplified language is made of up literals (variables
% $x$, regular expressions $\rett$, objects $\curlies{\var
%   \texttt{:}~e}$, and functions
% $\texttt{function}~x~\parens{x}~\curlies{e}$), expressions
% (parenthesized expressions $\parens{e}$, property lookup $e \texttt{.}
% \var$, function call $e \parens{e}$, binary expressions $e ~\div~ e$
% and $e ~\texttt{+}~ e$, and assignments $e ~\texttt{=}~ e$), and
% statements (blocks $\curlies{e}$, labelled statements $\var
% \texttt{:}~e$, if statements $\texttt{if}~\parens{e}~e$, return
% statements $\texttt{return}$ and $\texttt{return}~e$, function
% declarations $\texttt{function}~x~\parens{x}~\curlies{e}$, and
% statement sequences $e~e$).

\begin{displayfigure}{\label{fig:ast}AST for Simplified JavaScript}
\[
\begin{array}{rrl}
  e \in \textit{AST} &::=& \var ~|~ \rett ~|~ \curlies{\var\texttt{:}~e} ~|~ \parens{e}
  ~|~ e\texttt{.}\var ~|~ e\parens{e}
  \\
  &|& e~\div~e ~|~ e ~\texttt{+}~ e ~|~ e ~\texttt{=}~ e
  ~|~ \curlies{e} ~|~ \var \texttt{:} e ~|~ \texttt{if}~\parens{e}~e
  \\ 
  &|& \texttt{return} ~|~ \texttt{return}~e
  \\
  &|& \texttt{function}~x~\parens{x}~\curlies{e} ~|~ e~e
\end{array}
\]
\end{displayfigure}

The language presented here is a simplified for the sake of
presentation; it is mostly straightforward to extend the algorithm
presented here for the simplified language to 
the sweet.js implementation for full ES5 JavaScript.

In addition to the \( \gprod{Program}{} \) parser just described, we
also define a parser \( \gprod{Program'}{} \) that works over token
trees. The rules of the two parsers are similar except for that
all rules with delimiters and regular expression literals will change:

\[
\begin{array}{lcl}
  \gprod{PrimaryExpr}{\rett} &::=& \texttt{/}\cdot x \cdot \texttt{/}
  \\
  \gprod{PrimaryExpr'}{\rett} &::=& \rett
  \\
  \gprod{PrimaryExpr}{\parens{e}} &::=& 
  \texttt{(} \cdot \gprod{AssignExpr}{e} \cdot \texttt{)}
  \\
  \gprod{PrimaryExpr'}{\parens{e}} &::=& 
  \parens{\gprod{AssignExpr'}{e}}
  \\
\end{array}
\]

To prove that read is correct, we show that the following two parsing
strategies give identical behavior.
\begin{itemize}
\item The traditional parsing strategy is, given a token stream \( s
  \), to parse \( s \) into an AST \( e \) using a traditional parser.

\item The second parsing strategy first reads \( s \) into a token
  tree stream \( t = \readfn{s}{\epsilon}{\false} \), and then parses
  this token tree stream \( t \) into an AST \( e \).
\end{itemize}

\begin{theorem}[\label{thrm:readProgram}Parse Equivalence]\mbox{}

  \( \forall s. \)

  \( s \in \gprod{Program}{e} \Leftrightarrow 
  \readfn{s}{\epsilon}{\textit{false}} \in \gprod{Program'}{e} \)

\end{theorem}
\begin{proof}\mbox{}
  By showing parse equivalence for each non-terminal in the grammar.
  Details in the appendix.
\end{proof}

\begin{displayfigure*}{\label{fig:simpleread}Simplified Read Algorithm}
\begin{minipage}[t]{0.5\linewidth}
\[
\begin{array}{lrl}
  \textit{Punctuator} &::=& \div ~|~ \texttt{+} ~|~ \texttt{:} ~|~
  \texttt{;} ~|~ \texttt{=} ~|~ \texttt{.}
  \\
  \textit{Keyword} &::=& \texttt{return} ~|~ \texttt{function}~|~
  \texttt{if}
  \\
  \Tok &::=& \textit{Punctuator} ~|~ \textit{Keyword}
  \\
  && |~ x ~|~ \texttt{\{} ~|~ \texttt{(} ~|~ 
  \texttt {\}} ~|~  \texttt{)}
  \\
  \TT &::=& \textit{Punctuator} ~|~ \textit{Keyword}
  \\
  &&|~ x ~|~ \rett ~|~ \parens{t} ~|~ \curlies{t}
  \\
  x &\in& \textit{Variable}
  \\
  r &\in& \textit{RegexBody}
  \\
  s &\in& \Tok^{*}
  \\
  t,p &\in& \TT^{*}
\end{array}
\]
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
\[
  \begin{array}{lcll}
    \multicolumn{3}{l}{\textrm{isExprPrefix} : \TT^{*} \rightarrow
      \textit{Bool} \rightarrow \textit{Int}}
    \\
    \isobject(\epsilon,~\textit{true},~l) &=& \textit{true}
    \\
    \isobject(p \cdot \div,~b,~l) &=& \textit{true}
    \\
    \isobject(p \cdot \texttt{+},~b,~l) &=& \textit{true}
    \\
    \isobject(p \cdot \texttt{=},~b,~l) &=& \textit{true}
    \\
    \isobject(p \cdot \texttt{:},~b,~l) &=& b
    \\
    \isobject(p \cdot \texttt{return}^{l},~b,~l') &=& \textit{false} 
    & \textit{if}~l \not = l'
    \\
    \isobject(p \cdot \texttt{return}^{l},~b,~l') &=& \textit{true} 
    & \textit{if}~l = l'
    \\
    \isobject(p ,~b,~l) &=& \textit{false}
    \\
  \end{array}
\]
\end{minipage}
\[
  \begin{array}{lcll}
    \multicolumn{3}{l}{\textrm{read} : \Tok^{*} \rightarrow \TT^{*}
      \rightarrow \textit{Bool} \rightarrow \TT^{*}}
    \\
    % regex
    \readfn{/\cdot x \cdot /\cdot \vtok}{\epsilon}{b}
    &=&
    \cons{/x/}{
      \readfn{\vtok}{/x/}{b}
    }
    \\
    \readfn{/\cdot x \cdot /\cdot \vtok}{p \cdot p'}{b}
    &=&
    \cons{/x/}{
      \readfn{\vtok}{
        p \cdot p' \cdot /x/
      }{b}
    }
    \\
    \quad\textit{if}~p' \in \textit{Punctuator or Keyword}
    \\
    \readfn{/\cdot x \cdot /\cdot \vtok}{
      p \cdot \texttt{if} \cdot \parens{t}
    }{b}
    &=&
    \cons{/x/}{
      \readfn{\vtok}{p \cdot \texttt{if} \cdot \parens{t} \cdot /x/}{b}
    }
    \\
    \readfn{/\cdot x \cdot /\cdot \vtok}{
      p \cdot p' \cdot \texttt{function}^{l} \cdot x
      \cdot \parens{t} \cdot \curlies{t'}
    }{b}
    &=&
    \cons{/x/}{
      \readfn{\vtok}{
      p \cdot p' 
      \cdot \texttt{function}^{l} \cdot x \cdot 
      \parens{t} \cdot \curlies{t'}\cdot /x/
      }{b}
    } \\
    \quad \textit{if false}~=~ \isobject(p',~b,~l)
    \\
    \readfn{/\cdot x \cdot / \cdot \vtok}{
      p \cdot \curlies{t}^{l}
    }{b}
    &=&
    \cons{/x/}{
      \readfn{\vtok}{
        p \cdot \curlies{t}^{l}\cdot /x/
      }{b}
    }
    \\
    \quad \textit{where false} = \isobject(p,~b,~l)

    \\ \\

    % divide
    \readfn{/\cdot \vtok}{p\cdot x}{b}
    &=&
    \cons{/}{
      \readfn{\vtok}{
        p\cdot x\cdot /
      }{b}
    }
    \\
    \readfn{/\cdot \vtok}{p \cdot /x/}{b}
    &=&
    \cons{/}{
      \readfn{\vtok}{
        p \cdot /x/ \cdot /
      }{b}
    }
    \\
    \readfn{/\cdot \vtok}{p \cdot \parens{t}}{b}
    &=&
    \cons{/}{
      \readfn{\vtok}{
        p \cdot \parens{t} \cdot /
      }{b}
    }
    \\
    \readfn{/\cdot \vtok}{
      p \cdot p' \cdot \texttt{function}^l \cdot x
      \cdot \parens{t} \cdot \curlies{t'}
    }{b}
    &=&
    \cons{/}{
      \readfn{\vtok}{
        p \cdot p' \cdot \texttt{function}^l \cdot x \cdot \parens{t}
        \cdot \curlies{t'} \cdot /
      }{b}
    }
    \\
    \quad \textit{if true}~=~\isobject(p',~b,~l)
    \\
    \readfn{/\cdot \vtok}{
      p \cdot \curlies{t}^{l}
    }{b}
    &=&
    \cons{/}{
      \readfn{\vtok}{
        p \cdot \curlies{t}^{l} \cdot /
      }{b}
    }
    \\
    \quad \textit{where true} = \isobject(p,~b,~l)

    \\ \\
    

    % other
    \readfn{\texttt{(} \cdot \vtok \cdot \texttt{)} \cdot \vtok'}{p}{b}
    &=&
    \cons{\parens{t}}{
      \readfn{\vtok'}{p \cdot \parens{t}}{b}
    } 
    \\
    \quad \textit{where}~s~\textit{contains no unmatched}~\texttt{)} 
    &&\quad \textit{where}~t = \readfn{s}{\epsilon}{\textit{false}} 
    \\
    \readfn{
      \texttt{\{}^l \cdot \vtok \cdot \texttt{\}} \cdot \vtok'
    }{p}{b}
    &=&
    \cons{\curlies{t}^l}{
      \readfn{\vtok'}{
        p \cdot \curlies{t}^l
      }{b}
    } 
    \\
    \quad \textit{where}~s~\textit{contains no unmatched}~\texttt{\}} 
    && \textit{where}~t = \readfn{s}{\epsilon}{\isobject(p,~b,~l)}
    \\
    \readfn{x \cdot \vtok}{p}{b}
    &=&
    \cons{x}{
      \readfn{\vtok}{p \cdot x}{b}
    }
    \\
    \readfn{\epsilon}{p}{b}
    &=&
    \epsilon \\
  \end{array}
\]
\end{displayfigure*}


\begin{displayfigure*}{\label{fig:grammar}Simplified ES5 Grammar}
\[
\begin{array}{lcl}
  \gprod{PrimaryExpr}{x} &::=& x
  \\
  \gprod{PrimaryExpr}{\rett} &::=& \texttt{/} \cdot x \cdot \texttt{/}
  \\
  \gprod{PrimaryExpr}{\curlies{\var \texttt{:} e}} &::=& 
  \curlies{\cdot \var \cdot \texttt{:} \cdot  \gprod{AssignExpr}{e}
    \cdot }
  \\
  \gprod{PrimaryExpr}{\parens{e}} &::=& 
  \parens{\cdot \gprod{AssignExpr}{e} \cdot }
  \\ \\
  \gprod{MemberExpr}{e} &::=&
  \gprod{PrimaryExpr}{e}
  \\
  \gprod{MemberExpr}{e} &::=&
  \gprod{FunctionExpr}{e}
  \\
  \gprod{MemberExpr}{e\texttt{.\var}} &::=&
  \gprod{MemberExpr}{e} \cdot \texttt{.} \cdot \var
  \\ \\
  \gprod{CallExpr}{e~\parens{e'}} &::=& 
  \gprod{MemberExpr}{e} \cdot
  \parens{\cdot \gprod{AssignExpr}{e'} \cdot }
  \\
  \gprod{CallExpr}{e~\parens{e'}} &::=& 
  \gprod{CallExpr}{e} \cdot
  \parens{\cdot \gprod{AssignExpr}{e'} \cdot }
  \\
  \gprod{CallExpr}{e\texttt{.\var}} &::=& 
  \gprod{CallExpr}{e}~\texttt{.}~
  \var
  \\ \\
  \gprod{BinaryExpr}{e} &::=& \gprod{CallExpr}{e} \\
  \gprod{BinaryExpr}{e ~\div~ e'}
  &::=&
  \gprod{BinaryExpr}{e} \cdot \div \cdot  \gprod{BinaryExpr}{e'} \\
  \gprod{BinaryExpr}{e ~\plus~ e'}
  &::=&
  \gprod{BinaryExpr}{e} \cdot \plus \cdot \gprod{BinaryExpr}{e'}
  \\ \\
  \gprod{AssignExpr}{e} &::=&
  \gprod{BinaryExpr}{e}
  \\
  \gprod{AssignExpr}{e~\texttt{=}~e'} &::=&
  \gprod{CallExpr}{e} \cdot \texttt{=} \cdot
  \gprod{AssignExpr}{e'}
  \\ \\
  \gprod{StmtList}{e} &::=&
  \gprod{Stmt}{e}
  \\
  \gprod{StmtList}{e~e'} &::=&
  \gprod{StmtList}{e} \cdot
  \gprod{Stmt}{e'}
  \\ \\
  \gprod{Stmt}{\curlies{e}} &::=& 
  \curlies{\cdot \gprod{StmtList}{e}\cdot} 
  \\
  \gprod{Stmt}{\var\texttt{:}~e} &::=&
  \var\cdot \texttt{:}\cdot\gprod{Stmt}{e}
  \\
  \gprod{Stmt}{e} &::=& 
  \gprod{AssignExpr}{e} \cdot \texttt{;}
  \qquad  \textit{where lookahead \( \not =
    \texttt{\{} \) or \( \texttt{function} \)}
  \\
  \gprod{Stmt}{\texttt{if}~\parens{e}~e'} &::=& 
  \texttt{if}\cdot 
  \parens{\cdot \gprod{AssignExpr}{e} \cdot }\cdot \gprod{Stmt}{e'}
  \\
  \gprod{Stmt}{\texttt{return}} &::=& 
  \texttt{return}
  \\
  \gprod{Stmt}{\texttt{return}~e} &::=& 
  \texttt{return}\cdot \textrm{[no line terminator
    here]}~\gprod{AssignExpr}{e}\cdot \texttt{;}
  \\ \\
  \gprod{FunctionDecl}{\texttt{function}~x~\parens{x'}~\curlies{e}} 
  &::=&
  \texttt{function} \cdot x \cdot \parens{ \cdot x' \cdot}\cdot
  \curlies{\cdot \gprod{SourceElements}{e} \cdot}
  \\
  \gprod{FunctionExpr}{\texttt{function}~x~\parens{x'}~\curlies{e}} 
  &::=&
  \texttt{function} \cdot x \cdot \parens{ \cdot x' \cdot}\cdot
  \curlies{\cdot \gprod{SourceElements}{e} \cdot}
  \\ \\
  \gprod{SourceElement}{e} &::=& \gprod{Stmt}{e} 
  \\
  \gprod{SourceElement}{e} &::=& \gprod{FunctionDecl}{e}
  \\ \\

  \gprod{SourceElements}{e} &::=& \gprod{SourceElement}{e}
  \\
  \gprod{SourceElements}{e~e'} &::=&
  \gprod{SourceElements}{e}\cdot \gprod{SourceElement}{e'}
  \\ \\
  \gprod{Program}{e} &::=& \gprod{SourceElements}{e}
  \\
  \gprod{Program}{} &::=& \epsilon
\end{array}
\]  
\end{displayfigure*}

\section{Enforestation}
\label{sec:enforest}

The token tree structure produced by the reader is sufficient to
implement an expressive macro system for a fully delimited language
like Scheme. However since most of the syntax forms in a language like
JavaScript are only partially delimited, it is necessary to provide
additional structure during expansion that allows macros to manipulate
undelimited or partially delimited groups of tokens. As an example,
consider the \lstinline!let! macro described earlier:

\begin{lstlisting}
macro let {
  rule { $id = $init:expr } => {
    var $id = $init
  }
}
let x = 40 + 2;
// expands to:
// var x = 40 + 2;
\end{lstlisting}

Like many syntax forms in JavaScript the variable initialization
expression is an undelimited group of tokens. Building an expressive
macro system requires that the macro can match and manipulate patterns
such as an expression.

Sweet.js groups tokens by
transforming a token tree into a
\emph{term tree} through \emph{enforestation} \cite{Rafkind2013}.
Enforestation works by progressively recognizing syntax forms (\eg
literals, identifiers, expressions, and statements) during expansion.

A term tree is a kind of proto-AST that represents a partial parse of
the program. As the expander passes through the token tress, it
creates term trees that contain unexpanded sub trees that will be
expanded once all macro definitions have been discovered in the
current scope (as discussed in Section \ref{sec:macroBinding}).

For an example of how enforestation progresses, consider the following
use of the \lstinline!let! macro:
\begin{lstlisting}
macro let {
  rule { $id = $init:expr } => {
    var $id = $init
  }
}
function foo(x) {
  let y = 40 + 2;
  return x + y;
}
foo(100);
\end{lstlisting}
Enforestation begins by loading the \lstinline!let! macro into the
macro environment and converting the function declaration into a term
tree (we use angle brackets to denote a term tree). Notice that the
body of the function has not yet been enforested in the first pass.
\begin{lstlisting}
<fn: foo, 
 args: (x), 
 body: {
   let y = 40 + 2;
   return x + y;
 }>
foo(100);
\end{lstlisting}
Next, a term tree is created for the function call.
\begin{lstlisting}
<fn: foo, 
 params: (x), 
 body: {
   let y = 40 + 2;
   return x + y;
 }>
<call: foo, args: (100)>
\end{lstlisting}
On the second pass through the top level scope the expander moves into
the function body. The use of \lstinline!let! is expanded away and the
\lstinline!var! and \lstinline!return! term trees are created.
\begin{lstlisting}
<fn: foo, 
 params: (x), 
 body: {
   <id: x, init: <op: +, left: 40, right: 2>
   <return: <op: +, left: x right: y> 
 }>
<call: foo, args: (100)>
\end{lstlisting}

The additional structure provided by the term trees allow macros to
match undelimited groups of tokens like as binary expressions such as
\lstinline!<op: +, left: 40, right: 2>!.

The enforestation technique described here was first proposed for the
Honu language \cite{Rafkind2013}. We take their technique and extend
it with two features described in the following sections:
infix macros and the invoke pattern class.

\subsection{Infix Macros}
\label{sec:infix}
The macros we have described so far must all be prefixed by the macro
identifier and syntax after the macro name is matched. This is
sufficient for many kinds of macros but some syntax forms require the
macro identifier to sit between patterns.

For example, the upcoming ES6 version of JavaScript includes a
shorthand syntax for defining functions with arrow notation:

\begin{lstlisting}
id = (x) => x
// equivalent to:
// id = (function(x) { return x; }).bind(this);
\end{lstlisting}

One of the primary goals of sweet.js is to enable the kinds of syntax
extension previously only done by the standardization committee. But,
prefix macros are not capable of implementing syntax extensions like
arrow functions since the macro name (\lstinline!=>!) is in the middle
of its syntax arguments.

Honu addressed this need for more flexible syntax transformation forms
in a limited fashion via user definable unary and binary
operators\footnote{Sweet.js will also provide support for definable
  operators though at the time of this writing they have not yet been
  fully implemented.}. Definable operators provide the ability to set
custom precedence and associativity along with a syntax
transformation. For example, the exponentiation operator could be
defined as:
\begin{lstlisting}
operator ^ 10 left {$lhs, $rhs} => {
  Math.pow($lhs, $rhs)
}
2 ^ 100;
// expands to:
// Math.pow(2, 100);
\end{lstlisting}

Unfortunately, definable operators are limited in that their operands
must be expressions (this limitation allows setting custom precedence
and associativity rules). This means it is impossible to define syntax
forms such as arrow functions via definable operators since the
parameter list is not an expression.

To address this limitation, sweet.js introduces \emph{infix macros},
which allow a macro to match syntax that comes before the macro
identifier. Infix macros are defined by adding the keyword
\lstinline!infix! after the \lstinline!rule! or \lstinline!case!
keyword and placing a pipe (\lstinline!|!) in the pattern where the
macro name would appear (the pipe can be thought of as the cursor in
the token stream).

For example, the following infix macro implements arrow functions:
\begin{lstlisting}
macro => {
  rule infix {
    ($params ...) | { $body:expr }
  } => {
    function ($params ...) {
      return $body 
    }
  }
}

var id = (x) => x
\end{lstlisting}




Standard macro transformers are invoked with the sequence of tokens
following the macro identifier and then return a modified sequence of
tokens that are then expanded:
\[
\textit{transformer} : \TT^* \rightarrow \TT^*
\]
To implement infix macros, we modify the type of a transformer to
take two arguments, one for the tokens that precede the macro
identifier and the other with the tokens that follow. The transformer
may then consume from either ends as needed, yielding new preceding
and following tokens:
\[
\begin{array}{rcl}
  \textit{transfomer}_{\textit{infix}} &:& (\TT^*, \TT^*) 
  \\
  &\rightarrow& (\TT^*, \TT^*)
\end{array}
\]

A naive implementation of this transformer type will lead to brittle
edge cases. For example:
\begin{lstlisting}
bar(x) => x
\end{lstlisting}
Here the \lstinline!=>! macro is juxtaposed next to a function call,
which we did not intend to be valid syntax. The naive expansion results
in unparsable code:
\begin{lstlisting}
bar function(x) { return x; }
\end{lstlisting}

In more subtle cases, a naive expansion might result in code that
actually parses but has incorrect semantics, leading to a
debugging nightmare.

To avoid this problem we provide the macro transformer with both the
previous tokens and their term tree representation.
\[
\begin{array}{rcl}
  \textit{transfomer}_{\textit{infix}} &:& ((\TT^*, \textit{TermTree}^{*}), \TT^*) 
  \\
  &\rightarrow& (\TT^*, \TT^*)
\end{array}
\]
We verify that an infix macro only
matches previous tokens within boundaries delimited by 
the term trees. In our running example:
\begin{lstlisting}
bar(x) => x
\end{lstlisting}
is first enforested to:
\begin{lstlisting}
<call: bar, args: (x)> => x
\end{lstlisting}
before invoking the \lstinline!=>! transformer with both the tokens
\lstinline!bar(x)! and the term tree
\lstinline!<call: bar, args: (x)>!. When the macro attempts to match
just \lstinline!(x)!, it detects that the parentheses splits the term
tree \lstinline!<call: bar, args: (x)>! and fails the match.

While infix macros fill the gap left by definable operators and allow
us to write previously undefinable macros such as arrow functions,
they also come with two limitations. First, there is no way to set
custom precedence or associativity was with operators. It is unclear
if this is a fundamental limitation or if there is some technique that
might enable setting precedence and associativity for infix macros.
The second limitation is that the preceding tokens to an infix macro
must be first expanded. This means that any macros that occur before
an infix macro will be invoked first:
\begin{lstlisting}
macro id { rule { $x } => { $x }}
macro m {
  rule infix { $first $second | } => {
    $first + $second   
  }
}
foo("sweet")
id 100 m
// expands to:
// foo
// ("sweet") + 100
\end{lstlisting}
This behavior introduces an asymmetry between the kinds of syntax an
infix macro can match before its identifier and the kinds of syntax it
can match after since the syntax following the identifier can contain
unexpanded macros.

Even with these limitations infix macros work as a powerful complement
to definable operators and greatly extend the kinds of syntax forms
that can be written as a macro.

\subsection{Invoke and Pattern Classes}
\label{sec:invoke}

Extensibility is the guiding design principle of any expressive macro
system. Since the entire point of macros is to extend the expressive
power of the language, so too should the macro system itself be
extensible by users. To that end sweet.js provides a mechanism to
extend the patterns used by macros to match their arguments.

As motivation, consider the following macro that matches against
color options:
\begin{lstlisting}
macro colors_options {
  rule { (red) } => {
    ["#FF0000"]
  }
  rule { (green) } => {
    ["#00FF00"]
  }
  rule { (blue) } => {
    ["#0000FF"]
  }
}
r = colors_options (red)
g = colors_options (green)
// expands to:
// r = ["#FF0000"]
// g = ["#00FF00"]
\end{lstlisting}
Macros can have multiple rules and the first rule to match (from top
to bottom) is used. While this macro seems to work, attempting to
generalize it quickly leads to a mess:
\begin{lstlisting}
macro colors_options {
  rule { (red, red) } => {
    ["#FF0000", "#FF0000"]
  }
  rule { (red, green) } => {
    ["#FF0000", "#00FF00"]
  }
  rule { (red, blue) } => {
    ["#FF0000", "#0000FF"]
  }
  // ... etc.
}
r = colors_options (red, green)
g = colors_options (green, blue)
// expands to:
// r = ["#FF0000", "#00FF00"]
// g = ["#00FF00", "#0000FF"]
\end{lstlisting}
While it is possible to solve this problem through the use of case
macros, the declarative intent is quickly lost in a mess of 
token manipulation code.

Our solution to this is the \lstinline!:invoke! pattern class.
This pattern class takes as a parameter a macro name which is inserted
into the token tree stream before matching. If the inserted macro
successfully matches its arguments, the result of its expansion is
bound to the pattern variable. This makes declarative options simple
to write:
\begin{lstlisting}
macro color {
  rule { red } => { "#FF0000" }
  rule { green } => { "#00FF00" }
  rule { blue } => { "#0000FF" }
}
macro colors_options {
  rule { ($opt:invoke(color) (,) ...) } => { 
    [$opt (,) ...]
  }
}
colors_options (red, green, blue, blue)
// expands to:
// ["#FF0000", "#00FF00", "#0000FF", "#0000FF"]
\end{lstlisting}
Here the \lstinline!color! macro plays the role of enumerating the
valid colors that can be matched and bound to \lstinline!$opt!.
If the token is not in one of the rules for \lstinline!color! (\eg
\lstinline!orange!) the \lstinline!colors_options! macro will fail to match.

As a sweet added bit of sugar, the use of \lstinline!:invoke! can be
inferred by just using the name of a macro in scope (\ie
\lstinline!$opt:color! is equivalent to
\lstinline!$opt:invoke(color)!).

\begin{lstlisting}
macro color {
  rule { red } => { "#FF0000" }
  rule { green } => { "#00FF00" }
  rule { blue } => { "#0000FF" }
}
macro colors_options {
  rule { ($opt:color (,) ...) } => { 
    [$opt (,) ...]
  }
}
colors_options (red, green, blue, blue)
// expands to:
// ["#FF0000", "#00FF00", "#0000FF", "#0000FF"]
\end{lstlisting}

By using \lstinline!:invoke! macros writers can encode patterns
like alternates, optional tokens, keyword classes, numeric classes,
and more in a declarative style.

\textbf{todo: talk about honu-style custom pattern classes? requires
  explaining the pattern environment which might be too deep.}

% These macros may return an optional pattern environment which will be
% scoped and loaded into the invoking macro's pattern environment. This
% lets us define Honu-style pattern classes as simple macro-generating
% macros.

% \begin{lstlisting}
% macro color {
%   ...
% }
% macro number {
%   ...
% }
% // `pattern` is just a macro-generating macro
% pattern color_value { $color:color $num:number }

% macro color_options {
%   rule { ($opt:color_value (,) ...) } => {
%     var cols = [$opt$color (,) ...];
%     var nums = [$opt$num (,) ...];
%   }
% }

% \end{lstlisting}

\section{Hygiene}
\label{sec:hygiene}

Maintaining hygiene during macro expansion is perhaps the single most
critical feature of an expressive macro system. The hygiene condition
enables macros to be true syntactic \emph{abstractions} by removing
the burden of reasoning about a macro's implementation details from the
user of a macro.

Our implementation of hygiene for sweet.js follows the Scheme approach
\cite{Hieb1992,Flatt2012} of tracking the lexical context in each
syntax object.

\textbf{todo: do we need examples of hygiene?}

\subsection{Macro Binding Limitation} 
\label{sec:macroBinding}

Unfortunately, the syntax of JavaScript does place a limitations on
our system that is not present in Scheme. In Scheme, definitions and
uses of macros can be freely mixed in a given lexical scope. In
particular, a macro can be used in an internal definition before its definition:

\begin{lstlisting}[language=lisp]
(define (foo)
  (define y (id 100))
  (define-syntax-rule (id x) x)
  (+ y y))
;; expands to:
;; (define (foo)
;;   (define y 100)
;;   (+ y y))
\end{lstlisting}

In order to support mixing use and definition, the Scheme expander
must make multiple passes through a scope. First to register any macro
definitions and second to expand the macros that were discovered
during the first pass. Critically, during the first pass the expander
does not expand inside internal definitions.

For example, after the first pass of expansion the above example will become:
\begin{lstlisting}
(define (foo)
  (define y (id 100))
  (+ y y))
\end{lstlisting}
where the \lstinline!id! macro has been registered in the macro
environment. During the second pass, the expander will expand macros
inside of internal definitions and so the example becomes:
\begin{lstlisting}
(define (foo)
  (define y 100)
  (+ y y))
\end{lstlisting}

Scheme is able to defer expansion of macros inside of internal
definitions because internal definitions are fully delimited. The
expander can skip over all of the syntax inside of the delimiter
because there actually is an \emph{inside} to skip over. However, this
is not true for JavaScript since \lstinline!var! statements
(JavaScript's equivalent of Scheme's internal definitions) are not
delimited and so it is not possible to use a macro that has not yet
been defined in a \lstinline!var! statement in sweet.js.

For example, this will fail:

\begin{lstlisting}
function foo() {
  var y = id 100;
  macro id {
    rule { $x } => { $x }
  }
  return y + y;
}
// fails!
\end{lstlisting}
When the expander reaches the \lstinline!var! statement during the
first pass, it has not yet loaded the \lstinline!id! macro into the
macro environment and so \lstinline!id 100! will be left unexpanded.
Since \lstinline!id 100! is not a valid expression, this will fail to parse.
Without delimiters there is no way to defer expansion of the
right-hand side of a \lstinline!var! statement.

Though the expander cannot defer expansion of \lstinline!var!
statements, it still does two passes so that
the second pass can expand inside of delimiters. For example, a macro
can be used inside of a function body that appears before the macro definition:
\begin{lstlisting}
function foo() {
  return id 100;
}
macro id {
  rule { $x } => { $x }
}
// expands to:
// function foo() {
//   return 100;
// }
\end{lstlisting}

While it is unfortunate that the syntax of JavaScript prevents fully
general mixing of macro use and definition, the primary need for
flexible macro definition locations is when writing mutually recursive
macros, which is fully supported with our approach.

\section{Implementation}
\label{sec:implementation}

Sweet.js is written in JavaScript and runs in the major JS
environments (\ie the brower and node.js). This is in contrast to Honu
which translates its code to Racket code and reuses the hygienic
expansion machinery already built in Racket. While this simplifies
the implementation of Honu it also requires an installation of Racket
which in some cases is not feasible (\eg sweet.js is able to run in
mobile device browsers).


\section{Related Work}
\label{sec:related}

Earlier treatments of macro-by-example in \cite{Kohlbecker1987}.

\begin{itemize}
\item Scheme/Racket
\item Honu
\item Template Haskell
\item Nemerle \cite{Skalski2004}
\item Scala
\item Closure
\end{itemize}
\section{Conclusion}

\bibliographystyle{plain}
\bibliography{../../../../bibtex/sweet.js}

\appendix

\clearpage

\section{Read Proof}

\textbf{todo: define RegexPrefix/DivPrefix}

% To help reason about the prefixes in read we define two sets the
% contain the disjoint prefixes that determine either a slash should be
% a divide or the start of a regular expression:

% \[
% \begin{array}{lrl}
%  \reprefix &::=& \epsilon
%  \\
%  &|& p \cdot p' \quad \textit{if}~p' \in \textit{Punctuator or Keyword}
%  \\
%  &|& p \cdot \texttt{if}\cdot\parens{t}
%  \\
%  &|& p \cdot p' \cdot \texttt{if}\cdot\parens{t}
% \end{array}
% \]

\begin{theorem}[\label{thrm:readProgram}Parse Equivalence for Program]\mbox{}

  \( \forall s. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{Program}{e} \\
  \Leftrightarrow&
  \readfn{s}{\epsilon}{\textit{false}} \in \gprod{Program'}{e}
  \end{array}
  \]
\end{theorem}
\begin{proof}

  For the left-to-right direction, the are two production rules for 
  \( \gprod{Program}{e} \).
  \begin{itemize}
  \item \( s \in \epsilon \). The result is immediate.

  \item \( s \in \gprod{SourceElements}{e} \)
    this holds by Lemma~\ref{lem:readSourceElements}.
  \end{itemize}

  A similar argument holds for the right-to-left direction.
\end{proof}

\begin{lemma}[\label{lem:readSourceElements}Parse Equivalence for SourceElements]\mbox{}

  \( \forall s. \) 
  \[
  \begin{array}{rl}
  &s \in \gprod{SourceElements}{e} 
  \\
  \Leftrightarrow&
  \readfn{s}{\epsilon}{\textit{false}} \in \gprod{SourceElements'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there are two production rules for
  \( \gprod{SourceElements}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{SourceElement}{e} \). This holds by Lemma
    \ref{lem:readSourceElement}.
    
  \item \( s \in \gprod{SourceElements}{e}~\gprod{SourceElement}{e'} \).
    We have
    \( s = s' \cdot s'' \) where \( s' \in \gprod{SourceElements}{e}
    \) and \( s'' \in \gprod{SourceElement}{e'} \).
    \[
    \begin{array}{rcl}
      t &=& \readfn{s'\cdot s''}{\epsilon}{\textit{false}}
      \\
      &=& \readfn{s'}{\epsilon}{\false}\cdot  
      \readfn{s''}{\readfn{s'}{\epsilon}{\false}}{\false}
    \end{array}
    \]
    By induction \( \readfn{s'}{\epsilon}{\false} \in
    \gprod{SourceElements'}{e} \) and by Lemma
    \ref{lem:readSourceElement}, \( \readfn{s''}{
      \readfn{s'}{\epsilon}{\false}}{\false} \in \gprod{SourceElement'}{e'} \) (since
    by Lemma \ref{lem:readSourceElementPrefix}, \( 
    \readfn{s'}{\epsilon}{\false} \in \reprefix \)). Thus \( t \in
    \gprod{SourceElements'}{e~e'} \).
  \end{itemize}
  
  The argument is similar for the right-to-left direction.
\end{proof}


\begin{lemma}[\label{lem:readSourceElement}Parse Equivalence for SourceElement]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{SourceElement}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{\false} \in \gprod{SourceElement'}{e}
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there are two production rules for 
  \( \gprod{SourceElement}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{Stmt}{e} \).
    This holds by Lemma \ref{lem:readStmt} since \( p \in \reprefix \).
    
  \item \( s \in \gprod{FunctionDecl}{e} \). This holds by Lemma
    \ref{lem:readFunctionDecl}.
  \end{itemize}

  The argument is similar for the right-to-left direction.
\end{proof}

\begin{lemma}[\label{lem:readFunctionDecl}Parse Equivalence for FunctionDecl]\mbox{}
  
  \( \forall s, p, b. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{FunctionDecl}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{b} \in \gprod{FunctionDecl'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there is one production rule for
  \( \gprod{FunctionDecl}{e} \):
  \[ 
  \begin{array}{lcl}
  s \in
  \texttt{function}~x~\parens{x'}~\curlies{\gprod{SourceElements}{e}}
  \end{array}
  \]

 We have \( s = \texttt{function}~x~\parens{x}~\curlies{s'}
 \) where \( s' \in \gprod{SourceElements}{e} \) so:
 \[
 \begin{array}{rcl}
   t &=& \readfn{\texttt{function}~x~\parens{x}~\curlies{s'}}{p}{b}
   \\
   &=& \texttt{function}~x~\parens{x}~\curlies{t'}
 \end{array}
 \]
 where \( t' = \readfn{s'}{\epsilon}{\textit{false}} \). 
 Since by Lemma \ref{lem:readSourceElements},
 \( t' \in \gprod{SourceElements'}{e} \) we have \( t \in \gprod{FunctionDecl'}{\texttt{function}~x~\parens{x}~\curlies{e}} \).
 
 The argument is similar for the right-to-left direction.
\end{proof}

\begin{lemma}[\label{lem:readStmt}Parse Equivalence for Stmt]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{Stmt}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{\false} \in \gprod{Stmt'}{e}
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction we have several production rules for
  \( \gprod{Stmt}{e} \).
  \begin{itemize}

  \item \( s \in \curlies{\gprod{StmtList}{e}} \). We have \( s =
    \curlies{s'} \) where \( s' \in \gprod{StmtList}{e} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{\curlies{s'}}{p}{\false}
      \\
      &=& \curlies{t'}
    \end{array}
    \]
    where \( t' = \readfn{s'}{\epsilon}{\textit{false}} \). By Lemma
    \ref{lem:readStmtList}, \( t' \in \gprod{StmtList'}{e} \)
    so \( t \in \gprod{Stmt'}{\curlies{e}} \).


  \item \( s \in \gprod{AssignExpr}{e}~\texttt{;}
    \). We have \( s = s' \cdot \texttt{;} \) where \( s' \in
    \gprod{AssignExpr}{e} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{s'\cdot \texttt{;}}{p}{\false}
      \\
      &=& \readfn{s'}{p}{\false} \cdot \texttt{;}
    \end{array}
    \]
    Since \( p \in \reprefix \) by Lemma
    \ref{lem:readAssignExpr}, \( \readfn{s'}{p}{\false} \in
    \gprod{AssignExpr'}{e} \) we have \( t \in
    \gprod{Stmt'}{e} \).

  \item \( s \in \texttt{if}~ \parens{\gprod{AssignExpr}{e}}~
    \gprod{Stmt}{e'} \). We have \( s =
    \texttt{if}\cdot \parens{s'}\cdot s'' \) where \( s' \in
    \gprod{AssignExpr}{e} \) and \( s'' \in \gprod{Stmt}{e'} \).
    \[
    \begin{array}{rcl}
      t &=& \readfn{
        \texttt{if}\cdot \parens{s'}\cdot s'' 
      }{p}{\false}
      \\
      &=& \texttt{if} \cdot \parens{t'} \cdot t'' 
    \end{array}
    \]
    where 
    \[ 
    \begin{array}{lcl}
      t' &=& \readfn{s'}{\epsilon}{\false}
      \\
      t'' &=& \readfn{s''}{
        p \cdot \texttt{if} \cdot \parens{t'}
      }{\false}
    \end{array}
    \]
    By Lemma \ref{lem:readAssignExpr} \( t' \in
    \gprod{AssignExpr'}{e} \). By induction, 
    \( t'' \in \gprod{Stmt'}{e'} \) (since
    \( p \cdot \parens{t'} \in \reprefix \)). Thus \( t \in
    \gprod{Stmt'}{\texttt{if}~\parens{e}~e'} \).

  \item \( s \in \texttt{return} \). Since \( s = \texttt{return} \)
    and \( \readfn{s}{p}{\false} = \texttt{return} \in
    \gprod{Stmt'}{\texttt{return}} \) we have our result directly.

  \item \( s \in \texttt{return}~ \gprod{AssignExpr}{e} \texttt{;} \).
    We have \( s = \texttt{return}\cdot s' \cdot \texttt{;} \) where
    \( s' \in \gprod{AssignExpr}{e} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{\texttt{return} \cdot s' \cdot \texttt{;}}{p}{\false}
      \\
      &=& \texttt{return}\cdot \readfn{s'}{p \cdot \texttt{return}}{\false}
      \cdot \texttt{;}
    \end{array}
    \]
    By Lemma \ref{lem:readAssignExpr}, \( \readfn{s'}{p
      \cdot \texttt{return}}{\false} \in \gprod{AssignExpr'}{e}
    \) thus \( t \in \gprod{Stmt'}{\texttt{return}~e} \).

  \item \( s \in \var~\texttt{:}~\gprod{Stmt}{e} \). We have \( s =
    \var \cdot \texttt{:} \cdot s' \) where \( s' \in \gprod{Stmt}{e}
    \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{\var \cdot \texttt{:} \cdot s'}{p}{\false}
      \\
      &=& \var \cdot \texttt{:} \cdot 
      \readfn{s'}{
        p \cdot \var \cdot \texttt{:}
      }{\false}
    \end{array}
    \]
    By induction, \( \readfn{s'}{p \cdot \var \cdot
      \texttt{:}}{\false} \in \gprod{Stmt'}{e} \) so \( t \in
    \gprod{Stmt'}{\var~\texttt{:}~e} \).
  \end{itemize}

  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readStmtList}Parse Equivalence for StmtList]\mbox{}

  \( \forall s, p \in \reprefix. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{StmtList}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{\false} \in \gprod{StmtList'}{e}
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction we have two production rules for
  \( \gprod{StmtList}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{Stmt}{e} \).
    This follows by Lemma \ref{lem:readStmt} since \( p \in \reprefix \).

  \item \( s \in \gprod{StmtList}{e}~ \gprod{Stmt}{e'} \). So \( s =
    s' \cdot s'' \) where \( s' \in \gprod{StmtList}{e} \) and \( s''
    \in \gprod{Stmt}{e'} \). Then,
    \[
    \begin{array}{rcl}
      t &=& \readfn{s' \cdot s''}{p}{\false}
      \\
      &=& \readfn{s'}{p}{\false} \cdot \readfn{s''}{p 
        \cdot \readfn{s'}{p}{\false}}{\false}
    \end{array}
    \]
    By induction \( \readfn{s'}{p}{\false} \in \gprod{StmtList'}{e} \)
    and by Lemma \ref{lem:readStmt}, \( \readfn{s''}{p \cdot
      \readfn{s'}{p}{\false}}{\false} \in \gprod{Stmt'}{e'} \) (since
    by Lemma \ref{lem:readStmtPrefix}, \( p \cdot
    \readfn{s'}{p}{\false} \in \reprefix \)). Thus, \( t \in
    \gprod{StmtList'}{e~e'} \).
  \end{itemize}
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readAssignExpr}Parse Equivalence for
  AssignExpr]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  If \( b = \false \) then \( s \not = \texttt{\{} \cdot s' \). If \(
  b = \true \) then \( s \) is unconstrained.
  \[ 
  \begin{array}{rl}
  &s \in \gprod{AssignExpr}{e} 
  \\
  \Leftrightarrow&
  \readfn{s}{p}{b} \in \gprod{AssignExpr'}{e} 
  \end{array}
  \]
  
\end{lemma}
\begin{proof}
  The constraint on \( s \) when \( b \) is false is due to the
  lookahead check in the production \( \gprod{Stmt}{e} ::=
  \gprod{AssignExpr}{e}~\texttt{;} \). Lemma \ref{lem:readPrimaryExpr}
  will make use of this constraint.

  For the left-to-right direction we have two production rules for
  \( \gprod{AssignExpr}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{BinaryExpr}{e} \). This holds by Lemma
    \ref{lem:readBinaryExpr}.
    
  \item \( s \in \gprod{CallExpr}{e} ~\texttt{=}~
    \gprod{AssignExpr}{e'} \).
    Then \( s = s' \cdot \texttt{=} \cdot s'' \) where \( s' \in
    \gprod{CallExpr}{e} \) and \( s'' \in
    \gprod{AssignExpr}{e'} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{s' \cdot \texttt{=} \cdot s''}{p}{b}
      \\
      &=& \readfn{s'}{p}{b}
      \cdot \readfn{\texttt{=}\cdot s''}{p \cdot \readfn{s'}{p}{b}}{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot \texttt{=} \cdot
      \readfn{s''}{p \cdot \readfn{s'}{p}{b} \cdot \texttt{=}}{b}
    \end{array}
    \]
    Since \( p \in \reprefix \) by Lemma
    \ref{lem:readCallExpr}, \( \readfn{s'}{p}{b} \in
    \gprod{CallExpr'}{e} \) and by induction \( \readfn{s''}{p
      \cdot \readfn{s'}{p}{b} \cdot \texttt{=}}{b} \in
    \gprod{AssignExpr'}{e'} \) 
    (since \( p \cdot \readfn{s'}{p}{b} \cdot \texttt{=} \in \reprefix \)) so \( t \in
    \gprod{AssignExpr'}{e~\texttt{=}~e'} \).
  \end{itemize}
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readBinaryExpr}Parse Equivalence for BinaryExpr]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  If \( b = \false \) then \( s \not = \texttt{\{} \cdot s' \). If \(
  b = \true \) then \( s \) is unconstrained.
  \[
  \begin{array}{rl}
  &s \in \gprod{BinaryExpr}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{b} \in \gprod{BinaryExpr'}{e} 
  \end{array}
  \]

\end{lemma}
\begin{proof}
  For the left-to-right direction there are three productions for
  \( \gprod{BinaryExpr}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{CallExpr}{e} \). This holds by Lemma
    \ref{lem:readCallExpr} since \( p \in \reprefix \).

  \item \( s \in \gprod{BinaryExpr}{e} ~\div~ \gprod{BinaryExpr}{e'}
    \). We have \( s = s' \cdot \div \cdot s'' \) where \( s' \in
    \gprod{BinaryExpr}{e} \) and \( s'' \in \gprod{BinaryExpr}{e'} \).
    Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{s'\cdot \div \cdot s''}{p}{b}
      \\
      &=& 
      \readfn{s'}{p}{b} \cdot 
      \readfn{\div \cdot s''}{
        p \cdot \readfn{s'}{p}{b}
      }{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot \div \cdot 
      \readfn{s''}{
        p \cdot \readfn{s'}{p}{b} \cdot \div
      }{b}
      \\ 
      && \textrm{(since \( p \cdot \readfn{s'}{p}{b} \in \divprefix \))}
    \end{array}
    \]
    By induction \( \readfn{s'}{p}{b} \in \gprod{BinaryExpr'}{e} \)
    and \( 
      \readfn{s''}{
        p \cdot \readfn{s'}{p}{b} \cdot \div
      }{b} \in \gprod{BinaryExpr'}{e'}
      \) (since \( p \cdot \readfn{s'}{p}{b} \cdot \div \in \reprefix \)) thus \( t \in \gprod{BinaryExpr'}{e~\div~e'} \).

    \item \( s \in \gprod{BinaryExpr}{e} ~\texttt{+}~
      \gprod{BinaryExpr}{e'} \). We have \( s = s' \cdot \texttt{+}
      \cdot s'' \) where \( s' \in \gprod{BinaryExpr}{e} \) and \( s''
      \in \gprod{BinaryExpr}{e'} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{s'\cdot \texttt{+} \cdot s''}{p}{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot \texttt{+} \cdot 
      \readfn{s''}{
        p \cdot \readfn{s'}{p}{b} \cdot \texttt{+}
      }{b}
    \end{array}
    \]
    By induction \( \readfn{s'}{p}{b} \in \gprod{BinaryExpr'}{e}
    \) and \( \readfn{s''}{ p \cdot \readfn{s'}{p}{b} \cdot \texttt{+}
    }{b} \in \gprod{BinaryExpr'}{e'} \) (since \( p \cdot
    \readfn{s'}{p}{b} \cdot \texttt{+} \in \reprefix \)) thus \( t \in
    \gprod{BinaryExpr'}{e~\texttt{+}~e'} \).
  \end{itemize}
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readCallExpr}Parse Equivalence for CallExpr]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  If \( b = \false \) then \( s \not = \texttt{\{} \cdot s' \). If \(
  b = \true \) then \( s \) is unconstrained.
  \[ 
  \begin{array}{rl}
  &s \in \gprod{CallExpr}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{b} \in \gprod{CallExpr'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there are two production rules for
  \( \gprod{CallExpr}{e} \).
  \begin{itemize}
  \item \( s \in
    \gprod{MemberExpr}{e}~ \parens{\gprod{AssignExpr'}{e'}} \). We
    have \( s = s' \cdot \parens{s''} \) where \( s' \in
    \gprod{MemberExpr}{e} \) and \( s'' \in \gprod{AssignExpr}{e'} \).
    Then
    \[
    \begin{array}{rcl}
      t &=& \readfn{s' \cdot \parens{s''}}{p}{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot
      \readfn{\parens{s''}}{
        p \cdot \readfn{s'}{p}{b}
      }{b}
    \end{array}
    \]
    Since \( p \in \reprefix \), by Lemma
    \ref{lem:readMemberExpr} we have \( \readfn{s'}{p}{b} \in
    \gprod{MemberExpr'}{e} \) and my Lemma
    \ref{lem:readAssignExpr} we have
    \(\readfn{s''}{\epsilon}{\textit{false}} \in
    \gprod{AssignExpr'}{e'} \) thus \( t \in
    \gprod{CallExpr'}{e~\parens{e'}} \).

  \item \( s \in \gprod{CallExpr}{e} ~\texttt{.} ~\var \). Then \( s =
    s' \cdot \texttt{.}\cdot \var \) where \( s' \in
    \gprod{CallExpr}{e} \). Then
    \[
    \begin{array}{rcl}
      t &=& \readfn{s' \cdot \texttt{.} \cdot \var}{p}{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot \texttt{.}\cdot \var
    \end{array}
    \]
    By induction \( \readfn{s'}{p}{b} \in \gprod{CallExpr'}{e}
    \). Thus \( t \in \gprod{CallExpr'}{e~\texttt{.\var}} \).
  \end{itemize}
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readMemberExpr}Parse Equivalence for MemberExpr]\mbox{}

  \( \forall s, p \in \reprefix. \)
  If \( b = \false \) then \( s \not = \texttt{\{} \cdot s' \). If \(
  b = \true \) then \( s \) is unconstrained.
  \[
  \begin{array}{rl}
  &s \in \gprod{MemberExpr}{e} 
  \\
  \Leftrightarrow&
  \readfn{s}{p}{b} \in \gprod{MemberExpr'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there are two three production rules
  for \( \gprod{MemberExpr}{e} \).
  \begin{itemize}
  \item \( s \in \gprod{PrimaryExpr}{e} \). This follows from Lemma
    \ref{lem:readPrimaryExpr} since \( p \in \reprefix \).
    
  \item \( s \in \gprod{FunctionExpr}{e} \). This follows from Lemma
    \ref{lem:readFunctionExpr}.
    
  \item \( s \in \gprod{MemberExpr}{e} ~\texttt{.}~\var \). We have \(
    s = s' \cdot \texttt{.} \var \) where \( s \in
    \gprod{MemberExpr}{e} \). Then
    \[
    \begin{array}{rcl}
      t &=& \readfn{s' \cdot \texttt{.} \cdot \var}{p}{b}
      \\
      &=& \readfn{s'}{p}{b} \cdot \texttt{.} \cdot \var
    \end{array}
    \]
    By induction \( \readfn{s'}{p}{b} \in \gprod{MemberExpr'}{e}
    \) thus \( t \in \gprod{MemberExpr'}{e\texttt{.\var}} \).
  \end{itemize}
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readFunctionExpr}Parse Equivalence for
  FunctionExpr]\mbox{}

  \( \forall s, b, p \in \reprefix. \)
  \[
  \begin{array}{rl}
  &s \in \gprod{FunctionExpr}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{b} \in \gprod{FunctionExpr'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  Since \( s = \texttt{function}~x~\parens{x'}~\curlies{s'} \) where
  \( s' \in \gprod{SourceElements}{e} \) and 
  \[ 
  t = \readfn{s}{p}{b} = 
  \texttt{function} \cdot x \cdot \parens{x'} \cdot \curlies{t'}
  \]
  where \( t' = \readfn{s'}{\epsilon}{\false} \) and by Lemma
  \ref{lem:readSourceElements}, \( t' \in \gprod{SourceElements'}{e}
  \) we have \( t \in \gprod{FunctionExpr'}{\texttt{function}~x~\parens{x}~\curlies{e}} \).
  
  The argument for the right-to-left direction is similar.
\end{proof}

\begin{lemma}[\label{lem:readPrimaryExpr}Parse Equivalence for PrimaryExpr]\mbox{}
  
  \( \forall s, p \in \reprefix. \)
  If \( b = \false \) then \( s \not = \texttt{\{} \cdot s' \). If \(
  b = \true \) then \( s \) is unconstrained.
  \[ 
  \begin{array}{rl}
  &s \in \gprod{PrimaryExpr}{e} 
  \\
  \Leftrightarrow &
  \readfn{s}{p}{b} \in \gprod{PrimaryExpr'}{e} 
  \end{array}
  \]
\end{lemma}
\begin{proof}
  For the left-to-right direction there are several production rules for
  \( \gprod{PrimaryExpr}{e} \).
  \begin{itemize}
  \item \( s \in \var \). Then \( s
    = \var \) and \( \readfn{\var}{p}{b} \in
    \gprod{PrimaryExpr'}{\var} \) directly.

  \item \( s \in \re \). Then \( s
    = \re \) and \( \readfn{\re}{p}{b} = \rett \in
    \gprod{PrimaryExpr'}{\rett} \) since \( p \in \reprefix \).

  \item \( s \in \curlies{\var\texttt{:} \gprod{AssignExpr}{e}} \).
    Then \( s = \texttt{\{} \cdot \var \cdot \texttt{:} \cdot 
    s' \cdot \texttt{\}} \) where \(
    s' \in \gprod{AssignExpr}{e} \). Then:
    \[
    \begin{array}{rcl}
      t &=& \readfn{\texttt{\{} \cdot \var\cdot  
        \texttt{:} \cdot s' \cdot \texttt{\}}}{p}{\true}
      \\
      &=& \curlies{\var \cdot \texttt{:} \cdot t'}
    \end{array}
    \]
    where \( t' = \readfn{s'}{\var \cdot \texttt{:}}{\textit{true}} \). By Lemma
    \ref{lem:readAssignExpr}, \( t' \in
    \gprod{AssignExpr'}{e} \) and thus \( t \in
    \gprod{PrimaryExpr'}{\curlies{\var\texttt{:}e}} \).
    
  \item \( s \in \parens{\gprod{AssignExpr}{e}} \). Then \( s = \parens{s'} \)
    where \( s' \in \gprod{AssignExpr}{e} \). So,
    \[
    \begin{array}{rcl}
      t &=& \readfn{\parens{s'}}{p}{b}
      \\
      &=& \parens{t'}
    \end{array}
    \]
    where \( t' = \readfn{s'}{\epsilon}{\textit{false}} \). By Lemma
    \ref{lem:readAssignExpr} \( t' \in
    \gprod{AssignExpr'}{e} \). So, \( t \in
    \gprod{PrimaryExpr'}{\parens{e}} \).
  \end{itemize}
  
  For the right-to-left direction the argument is similar.
\end{proof}

\begin{lemma}[\label{lem:readSourceElementPrefix}SourceElement Prefix]\mbox{}
  
  \( \forall s, p \in \reprefix. \)

  \[
  \begin{array}{rl}
  &s \in \gprod{SourceElement}{e} 
  \\
  \Rightarrow &
  \readfn{s}{p}{\false} \in \reprefix
  \end{array}
  \]
\end{lemma}
\begin{proof}
  There are two cases:
  \begin{itemize}
  \item \( s \in \gprod{Stmt}{e} \). This holds by
    Lemma \ref{lem:readStmtPrefix}.

  \item \( s \in \gprod{FunctionDecl}{e} \). Follows directly.
  \end{itemize}
\end{proof}

\begin{lemma}[\label{lem:readStmtPrefix}Stmt Prefix]\mbox{}

  \( \forall s, p \in \reprefix. \)
  \[
  \begin{array}{rl}
  &\readfn{s}{p}{\false} \in \gprod{Stmt'}{e} 
  \\
  \Rightarrow& p \cdot \readfn{s}{p}{\false} \in \reprefix
  \end{array}
  \]
\end{lemma}
\begin{proof}
  We have several cases:
  \begin{itemize}
  \item \( \readfn{s}{p}{\false} \in \curlies{\gprod{StmtList'}{e}}
    \). Follows since \( p \in \reprefix \).

  \item \( \readfn{s}{p}{\false} \in \gprod{AssignExpr'}{e}~\texttt{;}
    \). Follows since \( t \cdot \texttt{;} \in \reprefix \) for any
    \( t \).
    
  \item \( t = \readfn{s}{p}{\false} \in \texttt{if}~\parens{\gprod{AssignExpr'}{e}}~\gprod{Stmt}{e'} \). Since
    \( t = \texttt{if}\cdot \parens{t'}\cdot t'' \) where \( t'' \in
    \gprod{Stmt'}{e'} \) by induction \( t'' \in \reprefix \) and
    thus \( p \cdot t \in \reprefix \).

  \item \( \readfn{s}{p}{\false} \in \texttt{return} \).
    Follows since \( p \cdot \texttt{return} \in \reprefix \).
    
  \item \( t = \readfn{s}{p}{\false} \in
    \texttt{return}~\gprod{AssignExpr'}{e}~ \texttt{;} \). 
    Since \( \texttt{;} \in \reprefix \) then \( p \cdot t \in
    \reprefix \).

  \item \( t = \readfn{s}{p}{\false} \in
    \var~\texttt{:}~\gprod{Stmt'}{e} \). Since \( t = \texttt{x}\cdot
    \texttt{:}\cdot t' \) where \( t' \in \gprod{Stmt'}{e} \). Since
    \( p \in \reprefix \) and by induction \( t' \in \reprefix \) we
    have \( p \cdot t \in \reprefix \).

  \end{itemize}
\end{proof}

\end{document}